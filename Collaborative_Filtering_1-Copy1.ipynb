{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In this project, We will analyze datasets containing data on restaurants, consumers and user-item-rating. The goal of this project is to implement Collaborative Filtering i.e., to find similarities between various consumers and recommend restaurants to consumers.\n",
    "\n",
    "The datasets for this project can be found on [Kaggle](https://www.kaggle.com/uciml/restaurant-data-with-consumer-ratings). \n",
    "\n",
    "The following code loads the datasets, along with a few of the necessary Python libraries required for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import scipy.stats\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading restaurant datasets\n",
      "Payment dataset has 1314 samples with 2 features each.\n",
      "Cuisine dataset has 916 samples with 2 features each.\n",
      "Hours dataset has 2339 samples with 3 features each.\n",
      "Parking dataset has 702 samples with 2 features each.\n",
      "Geo-places dataset has 130 samples with 21 features each.\n",
      "\n",
      "\n",
      "Loading consumer datasets\n",
      "Cuisine dataset has 330 samples with 2 features each.\n",
      "Payment dataset has 177 samples with 2 features each.\n",
      "Profile dataset has 138 samples with 19 features each.\n",
      "\n",
      "\n",
      "Loading User-Item-Rating dataset\n",
      "Rating dataset has 1161 samples with 5 features each.\n"
     ]
    }
   ],
   "source": [
    "print('Loading restaurant datasets')\n",
    "\n",
    "# Load Restaurant Payment dataset\n",
    "try:\n",
    "    rest_pay = pd.read_csv('chefmozaccepts.csv')\n",
    "    print('Payment dataset has %d samples with %d features each.' % (rest_pay.shape))\n",
    "except:\n",
    "    print('Payment dataset could not be loaded. Is the dataset missing?')\n",
    "    \n",
    "# Load the Restaurant Cuisine dataset\n",
    "try:\n",
    "    rest_cuisine = pd.read_csv('chefmozcuisine.csv')\n",
    "    print('Cuisine dataset has %d samples with %d features each.' % (rest_cuisine.shape))\n",
    "except:\n",
    "    print('Cuisine dataset could not be loaded. Is the dataset missing?')\n",
    "    \n",
    "# Load the Restaurant Hours dataset\n",
    "try:\n",
    "    rest_hours = pd.read_csv('chefmozhours4.csv')\n",
    "    print('Hours dataset has %d samples with %d features each.' % (rest_hours.shape))\n",
    "except:\n",
    "    print('Hours dataset could not be loaded. Is the dataset missing?')\n",
    "    \n",
    "# Load the Restaurant Parking dataset\n",
    "try:\n",
    "    rest_parking = pd.read_csv('chefmozparking.csv')\n",
    "    print('Parking dataset has %d samples with %d features each.' % (rest_parking.shape))\n",
    "except:\n",
    "    print('Parking dataset could not be loaded. Is the dataset missing?')\n",
    "\n",
    "#Load Restaurant Geo-places dataset\n",
    "try:\n",
    "    rest_geo = pd.read_csv('geoplaces2.csv')\n",
    "    print('Geo-places dataset has %d samples with %d features each.' % (rest_geo.shape))\n",
    "except:\n",
    "    print('Geo-places dataset could not be loaded. Is the dataset missing?')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Loading consumer datasets')\n",
    "\n",
    "# Load the Consumer Cuisine dataset\n",
    "try:\n",
    "    cons_cuisine = pd.read_csv('usercuisine.csv')\n",
    "    print('Cuisine dataset has %d samples with %d features each.' % (cons_cuisine.shape))\n",
    "except:\n",
    "    print('Cuisine dataset could not be loaded. Is the dataset missing?')\n",
    "\n",
    "#Load Consumer Payment dataset\n",
    "try:\n",
    "    cons_pay = pd.read_csv('userpayment.csv')\n",
    "    print('Payment dataset has %d samples with %d features each.' % (cons_pay.shape))\n",
    "except:\n",
    "    print('Payment dataset could not be loaded. Is the dataset missing?')\n",
    "\n",
    "#Load Consumer Profile dataset\n",
    "try:\n",
    "    cons_profile = pd.read_csv('userprofile.csv')\n",
    "    print('Profile dataset has %d samples with %d features each.' % (cons_profile.shape))\n",
    "except:\n",
    "    print('Profile dataset could not be loaded. Is the dataset missing?')\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print('Loading User-Item-Rating dataset')\n",
    "\n",
    "#Load Rating dataset\n",
    "try:\n",
    "    rating = pd.read_csv('rating_final.csv')\n",
    "    print('Rating dataset has %d samples with %d features each.' % (rating.shape))\n",
    "except:\n",
    "    print('Rating dataset could not be loaded. Is the dataset missing?')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Exploration\n",
    "\n",
    "In this section, we will begin exploring the data through visualizations and code to understand how features of each dataset are related to one another.\n",
    "\n",
    "Resturant datasets:<br>\n",
    "1. rest_pay: 'placeID', 'Rpayment'<br>\n",
    "2. rest_cuisine: 'placeID', 'Rcuisine' <br>\n",
    "3. rest_hours: 'placeID', 'hours', 'days' <br>\n",
    "4. rest_parking: 'placeID', 'parking_lot' <br>\n",
    "5. rest_geo: 'placeID', 'latitude', 'longitude', 'the_geom_meter', 'name', 'address','city', 'state', 'country', 'fax', 'zip', 'alcohol', 'smoking_area','dress_code', 'accessibility', 'price', 'url', 'Rambience', 'franchise','area', 'other_services'<br>\n",
    "\n",
    "User datasets:<br>\n",
    "1. cons_pay: 'userID', 'Upayment'<br>\n",
    "2. cons_cuisine: 'userID', 'Rcuisine'<br>\n",
    "3. cons_profile: 'userID', 'latitude', 'longitude', 'smoker', 'drink_level', 'dress_preference', 'ambience', 'transport', 'marital_status', 'hijos', 'birth_year', 'interest', 'personality', 'religion', 'activity', 'color', 'weight', 'budget', 'height' <br>\n",
    "\n",
    "Rating dataset:\n",
    "1. rating: 'userID', 'placeID', 'rating', 'food_rating', 'service_rating'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    }
   ],
   "source": [
    "#No.of users who are given ratings to the restaurants\n",
    "list_users = rating.userID.unique()\n",
    "print(len(list_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Merge all the restaurant dataframes into one\n",
    "# from functools import reduce\n",
    "# df = [rest_cuisine,rest_hours,rest_parking,rest_geo]\n",
    "# rest_final = reduce(lambda left,right: pd.merge(left,right,on='placeID'), df)\n",
    "# print(rest_final.columns)\n",
    "\n",
    "# #Merge all the user dataframes into one\n",
    "# df = [cons_cuisine,cons_profile]\n",
    "# cons_final = reduce(lambda left,right: pd.merge(left,right,on='userID'), df)\n",
    "# print(cons_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete users from cons_profile who have not given ratings\n",
    "for index, row in cons_profile.iterrows():\n",
    "    if row['userID'] not in list_users:\n",
    "        del row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remove features which are not useful for recommendation\n",
    "# rest_final = rest_final.drop(['url'], axis = 1) #not useful as most of the values are '?'\n",
    "# rest_final = rest_final.drop(['fax'], axis = 1) #all the values are '?'\n",
    "# rest_final = rest_final.drop(['country','state','city','zip','address'], axis = 1) #Not useful as we can directly\n",
    "#                                                                                    #use latitudes and logitudes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Scatter matrix for continuous values in the user dataset\n",
    "# pd.plotting.scatter_matrix(cons_final, alpha = 0.3, figsize = (20,20), diagonal = 'kde')\n",
    "# #From the graph below, we know that there's a correlation between weight and height and therefore we can remove one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remove Height since it shows high correlation with Weight\n",
    "cons_profile = cons_profile.drop('height', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and replacing missing values in the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer:\n",
      " userID              False\n",
      "latitude            False\n",
      "longitude           False\n",
      "smoker               True\n",
      "drink_level         False\n",
      "dress_preference     True\n",
      "ambience             True\n",
      "transport            True\n",
      "marital_status       True\n",
      "hijos                True\n",
      "birth_year          False\n",
      "interest            False\n",
      "personality         False\n",
      "religion            False\n",
      "activity             True\n",
      "color               False\n",
      "weight              False\n",
      "budget               True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#The code below gives True if any of the attributes contain missing values\n",
    "# print('Retaurant:\\n',rest_final.isin(['?']).any(), end = '\\n\\n')\n",
    "print('Customer:\\n',cons_profile.isin(['?']).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store indices of features having 'Nan' or '?' values\n",
    "indices = set() #to store unique values\n",
    "for index,row in cons_profile.iterrows():\n",
    "    for i in range(len(row)):\n",
    "        if row[i] is np.nan or row [i] is '?':\n",
    "            indices.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smoker', 'dress_preference', 'ambience', 'transport', 'marital_status', 'hijos', 'activity', 'budget']\n"
     ]
    }
   ],
   "source": [
    "#Features having 'Nan' or '?' values\n",
    "missing = list(cons_profile.columns[list(indices)])\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#Only the features with categorical data have missing values\n",
    "#Replace 'Nan' or '?' with a random value from the feature\n",
    "import random \n",
    "for attr in missing:\n",
    "    uni = list(cons_profile[attr].unique()) #List of all unique values in the feature\n",
    "    if '?' in uni:\n",
    "        uni.remove('?') #remove '?' if present in the list\n",
    "    if np.nan in uni:\n",
    "        uni.remove(np.nan) #remove 'Nan' if present in the list\n",
    "    i=0\n",
    "    for value in cons_profile[attr]: \n",
    "        if value is np.nan or value is '?':\n",
    "            cons_profile[attr][i] = cons_profile[attr][i].replace(value,random.choice(uni)) #replace it with a random item from the list\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cons_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding String/Object type data into Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cons_profile['smoker'] = le.fit_transform(cons_profile['smoker'])\n",
    "cons_profile['drink_level'] = le.fit_transform(cons_profile['drink_level'])\n",
    "cons_profile['dress_preference'] = le.fit_transform(cons_profile['dress_preference'])\n",
    "cons_profile['ambience'] = le.fit_transform(cons_profile['ambience'])\n",
    "cons_profile['transport'] = le.fit_transform(cons_profile['transport'])\n",
    "cons_profile['marital_status'] = le.fit_transform(cons_profile['marital_status'])\n",
    "cons_profile['hijos'] = le.fit_transform(cons_profile['hijos'])\n",
    "cons_profile['interest'] = le.fit_transform(cons_profile['interest'])\n",
    "cons_profile['personality'] = le.fit_transform(cons_profile['personality'])\n",
    "cons_profile['religion'] = le.fit_transform(cons_profile['religion'])\n",
    "cons_profile['activity'] = le.fit_transform(cons_profile['activity'])\n",
    "cons_profile['color'] = le.fit_transform(cons_profile['color'])\n",
    "cons_profile['budget'] = le.fit_transform(cons_profile['budget'])\n",
    "# cons_profile['Upayment'] = le.fit_transform(cons_profile['Upayment'])\n",
    "# cons_profile['Rcuisine'] = le.fit_transform(cons_profile['Rcuisine'])\n",
    "\n",
    "\n",
    "# rest_final['Rpayment'] = le.fit_transform(rest_final['Rpayment'])\n",
    "# rest_final['parking_lot'] = le.fit_transform(rest_final['parking_lot'])\n",
    "# rest_final['Rcuisine'] = le.fit_transform(rest_final['Rcuisine'])\n",
    "# rest_final['days'] = le.fit_transform(rest_final['days'])\n",
    "# rest_final['the_geom_meter'] = le.fit_transform(rest_final['the_geom_meter'])\n",
    "# rest_final['name'] = le.fit_transform(rest_final['name'])\n",
    "# rest_final['smoking_area'] = le.fit_transform(rest_final['smoking_area'])\n",
    "# rest_final['dress_code'] = le.fit_transform(rest_final['dress_code'])\n",
    "# rest_final['price'] = le.fit_transform(rest_final['price'])\n",
    "# rest_final['alcohol'] = le.fit_transform(rest_final['alcohol'])\n",
    "# rest_final['Rambience'] = le.fit_transform(rest_final['Rambience'])\n",
    "# rest_final['accessibility'] = le.fit_transform(rest_final['accessibility'])\n",
    "# rest_final['franchise'] = le.fit_transform(rest_final['franchise'])\n",
    "# rest_final['area'] = le.fit_transform(rest_final['area'])\n",
    "# rest_final['other_services'] = le.fit_transform(rest_final['other_services'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "cons_profile = shuffle(cons_profile)\n",
    "test_size = int(0.3*len(cons_profile))\n",
    "cons_test = cons_profile[-test_size:]\n",
    "cons_train = cons_profile[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(cons_train['latitude'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.735698 23.733    22.156469 22.118464 23.753112 22.122989 22.207749\n",
      " 22.162562 23.73944  22.150683 18.871674 22.149654 22.139997 23.753336\n",
      " 22.15     22.146708 23.730569 22.168997 22.174624 18.952615 22.153385\n",
      " 23.752269 19.347641 22.152884 22.169184 22.160572 18.879729 22.154339\n",
      " 18.927072 22.19204  22.143524 23.724972 18.925773 22.143078 22.139511\n",
      " 22.190949 23.77103  22.138245 18.813348 22.205802]\n"
     ]
    }
   ],
   "source": [
    "print(cons_train['latitude'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.cut(cons_train['latitude'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21.292, 23.771]    34\n",
      "(18.808, 21.292]     7\n",
      "Name: latitude, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(temp.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cons_train['latitude'] = pd.cut(cons_train['latitude'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30     (21.292, 23.771]\n",
      "25     (21.292, 23.771]\n",
      "75     (21.292, 23.771]\n",
      "6      (21.292, 23.771]\n",
      "122    (21.292, 23.771]\n",
      "Name: latitude, dtype: category\n",
      "Categories (2, interval[float64]): [(18.808, 21.292] < (21.292, 23.771]]\n"
     ]
    }
   ],
   "source": [
    "print(cons_train['latitude'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.cut(cons_train['longitude'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-101.001, -100.033]    24\n",
      "(-100.033, -99.067]     17\n",
      "Name: longitude, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(temp.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cons_train['longitude'] = pd.cut(cons_train['longitude'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    userID          latitude             longitude  smoker  drink_level  \\\n",
      "30   U1031  (21.292, 23.771]   (-100.033, -99.067]       0            0   \n",
      "25   U1026  (21.292, 23.771]   (-100.033, -99.067]       0            0   \n",
      "75   U1076  (21.292, 23.771]  (-101.001, -100.033]       0            2   \n",
      "6    U1007  (21.292, 23.771]  (-101.001, -100.033]       0            1   \n",
      "122  U1123  (21.292, 23.771]   (-100.033, -99.067]       0            0   \n",
      "\n",
      "     dress_preference  ambience  transport  marital_status  hijos  birth_year  \\\n",
      "30                  2         2          2               0      2        1992   \n",
      "25                  1         0          2               1      1        1989   \n",
      "75                  0         0          2               0      2        1987   \n",
      "6                   2         2          2               1      1        1989   \n",
      "122                 2         0          0               1      1        1987   \n",
      "\n",
      "     interest  personality  religion  activity  color  weight  budget  \n",
      "30          1            1         0         2      6      40       2  \n",
      "25          3            2         0         1      5      49       2  \n",
      "75          3            3         0         1      1      65       2  \n",
      "6           4            3         0         1      4      60       1  \n",
      "122         3            1         0         1      2     110       2  \n"
     ]
    }
   ],
   "source": [
    "print(cons_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "info  = []\n",
    "for index,row in cons_test.iterrows():\n",
    "    if row['userID'] == 'U1129':\n",
    "        for attr in row:\n",
    "            info.append(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U1129', 23.728798, -99.134047, 0, 1, 3, 1, 2, 1, 1, 1989, 4, 3, 4, 1, 4, 69, 1]\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userID                            U1011\n",
      "latitude               (21.292, 23.771]\n",
      "longitude           (-100.033, -99.067]\n",
      "smoker                                0\n",
      "drink_level                           0\n",
      "dress_preference                      3\n",
      "ambience                              0\n",
      "transport                             2\n",
      "marital_status                        1\n",
      "hijos                                 1\n",
      "birth_year                         1989\n",
      "interest                              4\n",
      "personality                           1\n",
      "religion                              0\n",
      "activity                              1\n",
      "color                                 4\n",
      "weight                               68\n",
      "budget                                2\n",
      "Name: 10, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for index,row in cons_train.iterrows():\n",
    "    if row[0] == 'U1011':\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_user(userid):\n",
    "    info  = []\n",
    "    for index,row in cons_test.iterrows():\n",
    "        if row['userID'] == userid:\n",
    "            for attr in row:\n",
    "                info.append(attr)\n",
    "    users = {}\n",
    "    res = []\n",
    "    count=0\n",
    "    points = 0\n",
    "    maxi = 0\n",
    "    similar = ''\n",
    "    for index,row in cons_train.iterrows():\n",
    "        points = 0\n",
    "        for i in range(len(row)-1):\n",
    "            if i == 1 or i==2:\n",
    "                if info[i] in row[i]:\n",
    "                    points+=1\n",
    "            if info[i] == row[i]:\n",
    "                points+=1\n",
    "        users[row[0]] = points\n",
    "        \n",
    "    for userid, value in sorted(users.items(), key=lambda x: x[1], reverse = True)[:5]:\n",
    "        res.append(userid)\n",
    "    return res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1111 132845 2 2 1\n",
      "U1111 135071 2 2 2\n",
      "U1111 132858 1 1 1\n",
      "U1111 132854 2 2 2\n",
      "U1111 132877 1 1 1\n",
      "U1111 132851 2 1 0\n",
      "U1111 135108 2 1 0\n",
      "U1111 132869 0 0 0\n",
      "U1111 132870 0 0 0\n",
      "U1111 132847 0 0 0\n",
      "U1111 135082 1 0 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rating)):\n",
    "    if rating.userID[i] == 'U1111':\n",
    "        print(rating.userID[i], rating.placeID[i], rating.rating[i], rating.food_rating[i], rating.service_rating[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum(usr):\n",
    "    max = 0\n",
    "    temp =  rating\n",
    "    MaxList = []\n",
    "    avg = []\n",
    "    x = []\n",
    "    for i in range(len(rating)):\n",
    "        if(rating.userID[i] == usr):\n",
    "            average = (rating.rating[i] + rating.food_rating[i] + rating.service_rating[i])/3\n",
    "            avg.append(average)\n",
    "            col = temp.loc[: , \"rating\":\"service_rating\"]\n",
    "            x = col.mean(numeric_only=True, axis=1)\n",
    "            temp['average'] = x\n",
    "    avg.sort(reverse = True)\n",
    "    for i in range(len(rating)):\n",
    "        if(temp.userID[i] == usr):\n",
    "            if(avg[0] == temp.average[i] and avg[0] != 0):\n",
    "                MaxList.append(rating.placeID[i])\n",
    "    return MaxList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'U1019': [], 'U1007': [135057, 135058], 'U1087': [132667, 132732], 'U1011': [132717], 'U1094': [135108]}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "usr = 'U1129'\n",
    "a = []\n",
    "userList = similar_user(usr)\n",
    "place = {}\n",
    "i=0\n",
    "for value in userList:\n",
    "    val = maximum(value)\n",
    "    place[value] = val\n",
    "print(place)\n",
    "print(len(place))\n",
    "# maximum('U1129')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
