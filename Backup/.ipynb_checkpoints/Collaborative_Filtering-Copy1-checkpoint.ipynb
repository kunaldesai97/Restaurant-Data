{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In this project, We will analyze datasets containing data on restaurants, consumers and user-item-rating. The goal of this project is to implement Collaborative Filtering i.e., to find similarities between various consumers and recommend restaurants to consumers.\n",
    "\n",
    "The datasets for this project can be found on [Kaggle](https://www.kaggle.com/uciml/restaurant-data-with-consumer-ratings). \n",
    "\n",
    "The following code loads the datasets, along with a few of the necessary Python libraries required for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading restaurant datasets\n",
      "Payment dataset has 1314 samples with 2 features each.\n",
      "Cuisine dataset has 916 samples with 2 features each.\n",
      "Hours dataset has 2339 samples with 3 features each.\n",
      "Parking dataset has 702 samples with 2 features each.\n",
      "Geo-places dataset has 130 samples with 21 features each.\n",
      "\n",
      "\n",
      "Loading consumer datasets\n",
      "Cuisine dataset has 330 samples with 2 features each.\n",
      "Payment dataset has 177 samples with 2 features each.\n",
      "Profile dataset has 138 samples with 19 features each.\n",
      "\n",
      "\n",
      "Loading User-Item-Rating dataset\n",
      "Rating dataset has 1161 samples with 5 features each.\n"
     ]
    }
   ],
   "source": [
    "print('Loading restaurant datasets')\n",
    "\n",
    "# Load Restaurant Payment dataset\n",
    "try:\n",
    "    rest_pay = pd.read_csv('chefmozaccepts.csv')\n",
    "    print('Payment dataset has %d samples with %d features each.' % (rest_pay.shape))\n",
    "except:\n",
    "    print('Payment dataset could not be loaded. Is the dataset missing?')\n",
    "    \n",
    "# Load the Restaurant Cuisine dataset\n",
    "try:\n",
    "    rest_cuisine = pd.read_csv('chefmozcuisine.csv')\n",
    "    print('Cuisine dataset has %d samples with %d features each.' % (rest_cuisine.shape))\n",
    "except:\n",
    "    print('Cuisine dataset could not be loaded. Is the dataset missing?')\n",
    "    \n",
    "# Load the Restaurant Hours dataset\n",
    "try:\n",
    "    rest_hours = pd.read_csv('chefmozhours4.csv')\n",
    "    print('Hours dataset has %d samples with %d features each.' % (rest_hours.shape))\n",
    "except:\n",
    "    print('Hours dataset could not be loaded. Is the dataset missing?')\n",
    "    \n",
    "# Load the Restaurant Parking dataset\n",
    "try:\n",
    "    rest_parking = pd.read_csv('chefmozparking.csv')\n",
    "    print('Parking dataset has %d samples with %d features each.' % (rest_parking.shape))\n",
    "except:\n",
    "    print('Parking dataset could not be loaded. Is the dataset missing?')\n",
    "\n",
    "#Load Restaurant Geo-places dataset\n",
    "try:\n",
    "    rest_geo = pd.read_csv('geoplaces2.csv')\n",
    "    print('Geo-places dataset has %d samples with %d features each.' % (rest_geo.shape))\n",
    "except:\n",
    "    print('Geo-places dataset could not be loaded. Is the dataset missing?')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Loading consumer datasets')\n",
    "\n",
    "# Load the Consumer Cuisine dataset\n",
    "try:\n",
    "    cons_cuisine = pd.read_csv('usercuisine.csv')\n",
    "    print('Cuisine dataset has %d samples with %d features each.' % (cons_cuisine.shape))\n",
    "except:\n",
    "    print('Cuisine dataset could not be loaded. Is the dataset missing?')\n",
    "\n",
    "#Load Consumer Payment dataset\n",
    "try:\n",
    "    cons_pay = pd.read_csv('userpayment.csv')\n",
    "    print('Payment dataset has %d samples with %d features each.' % (cons_pay.shape))\n",
    "except:\n",
    "    print('Payment dataset could not be loaded. Is the dataset missing?')\n",
    "\n",
    "#Load Consumer Profile dataset\n",
    "try:\n",
    "    cons_profile = pd.read_csv('userprofile.csv')\n",
    "    print('Profile dataset has %d samples with %d features each.' % (cons_profile.shape))\n",
    "except:\n",
    "    print('Profile dataset could not be loaded. Is the dataset missing?')\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print('Loading User-Item-Rating dataset')\n",
    "\n",
    "#Load Rating dataset\n",
    "try:\n",
    "    rating = pd.read_csv('rating_final.csv')\n",
    "    print('Rating dataset has %d samples with %d features each.' % (rating.shape))\n",
    "except:\n",
    "    print('Rating dataset could not be loaded. Is the dataset missing?')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Exploration\n",
    "\n",
    "In this section, we will begin exploring the data through visualizations and code to understand how features of each dataset are related to one another.\n",
    "\n",
    "Resturant datasets:<br>\n",
    "1. rest_pay: 'placeID', 'Rpayment'<br>\n",
    "2. rest_cuisine: 'placeID', 'Rcuisine' <br>\n",
    "3. rest_hours: 'placeID', 'hours', 'days' <br>\n",
    "4. rest_parking: 'placeID', 'parking_lot' <br>\n",
    "5. rest_geo: 'placeID', 'latitude', 'longitude', 'the_geom_meter', 'name', 'address','city', 'state', 'country', 'fax', 'zip', 'alcohol', 'smoking_area','dress_code', 'accessibility', 'price', 'url', 'Rambience', 'franchise','area', 'other_services'<br>\n",
    "\n",
    "User datasets:<br>\n",
    "1. cons_pay: 'userID', 'Upayment'<br>\n",
    "2. cons_cuisine: 'userID', 'Rcuisine'<br>\n",
    "3. cons_profile: 'userID', 'latitude', 'longitude', 'smoker', 'drink_level', 'dress_preference', 'ambience', 'transport', 'marital_status', 'hijos', 'birth_year', 'interest', 'personality', 'religion', 'activity', 'color', 'weight', 'budget', 'height' <br>\n",
    "\n",
    "Rating dataset:\n",
    "1. rating: 'userID', 'placeID', 'rating', 'food_rating', 'service_rating'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    }
   ],
   "source": [
    "#No.of users who are given ratings to the restaurants\n",
    "list_users = rating.userID.unique()\n",
    "print(len(list_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Merge all the restaurant dataframes into one\n",
    "# from functools import reduce\n",
    "# df = [rest_cuisine,rest_hours,rest_parking,rest_geo]\n",
    "# rest_final = reduce(lambda left,right: pd.merge(left,right,on='placeID'), df)\n",
    "# print(rest_final.columns)\n",
    "\n",
    "# #Merge all the user dataframes into one\n",
    "# df = [cons_cuisine,cons_profile]\n",
    "# cons_final = reduce(lambda left,right: pd.merge(left,right,on='userID'), df)\n",
    "# print(cons_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Delete users from cons_profile who have not given ratings\n",
    "for index, row in cons_profile.iterrows():\n",
    "    if row['userID'] not in list_users:\n",
    "        del row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Remove features which are not useful for recommendation\n",
    "# rest_final = rest_final.drop(['url'], axis = 1) #not useful as most of the values are '?'\n",
    "# rest_final = rest_final.drop(['fax'], axis = 1) #all the values are '?'\n",
    "# rest_final = rest_final.drop(['country','state','city','zip','address'], axis = 1) #Not useful as we can directly\n",
    "#                                                                                    #use latitudes and logitudes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Scatter matrix for continuous values in the user dataset\n",
    "# pd.plotting.scatter_matrix(cons_final, alpha = 0.3, figsize = (20,20), diagonal = 'kde')\n",
    "# #From the graph below, we know that there's a correlation between weight and height and therefore we can remove one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Remove Height since it shows high correlation with Weight\n",
    "cons_profile = cons_profile.drop('height', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and replacing missing values in the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer:\n",
      " userID              False\n",
      "latitude            False\n",
      "longitude           False\n",
      "smoker               True\n",
      "drink_level         False\n",
      "dress_preference     True\n",
      "ambience             True\n",
      "transport            True\n",
      "marital_status       True\n",
      "hijos                True\n",
      "birth_year          False\n",
      "interest            False\n",
      "personality         False\n",
      "religion            False\n",
      "activity             True\n",
      "color               False\n",
      "weight              False\n",
      "budget               True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#The code below gives True if any of the attributes contain missing values\n",
    "# print('Retaurant:\\n',rest_final.isin(['?']).any(), end = '\\n\\n')\n",
    "print('Customer:\\n',cons_profile.isin(['?']).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Store indices of features having 'Nan' or '?' values\n",
    "indices = set() #to store unique values\n",
    "for index,row in cons_profile.iterrows():\n",
    "    for i in range(len(row)):\n",
    "        if row[i] is np.nan or row [i] is '?':\n",
    "            indices.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smoker', 'dress_preference', 'ambience', 'transport', 'marital_status', 'hijos', 'activity', 'budget']\n"
     ]
    }
   ],
   "source": [
    "#Features having 'Nan' or '?' values\n",
    "missing = list(cons_profile.columns[list(indices)])\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#Only the features with categorical data have missing values\n",
    "#Replace 'Nan' or '?' with a random value from the feature\n",
    "import random \n",
    "for attr in missing:\n",
    "    uni = list(cons_profile[attr].unique()) #List of all unique values in the feature\n",
    "    if '?' in uni:\n",
    "        uni.remove('?') #remove '?' if present in the list\n",
    "    if np.nan in uni:\n",
    "        uni.remove(np.nan) #remove 'Nan' if present in the list\n",
    "    i=0\n",
    "    for value in cons_profile[attr]: \n",
    "        if value is np.nan or value is '?':\n",
    "            cons_profile[attr][i] = cons_profile[attr][i].replace(value,random.choice(uni)) #replace it with a random item from the list\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cons_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding String/Object type data into Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# cons_profile['smoker'] = le.fit_transform(cons_profile['smoker'])\n",
    "# cons_profile['drink_level'] = le.fit_transform(cons_profile['drink_level'])\n",
    "# cons_profile['dress_preference'] = le.fit_transform(cons_profile['dress_preference'])\n",
    "# cons_profile['ambience'] = le.fit_transform(cons_profile['ambience'])\n",
    "# cons_profile['transport'] = le.fit_transform(cons_profile['transport'])\n",
    "# cons_profile['marital_status'] = le.fit_transform(cons_profile['marital_status'])\n",
    "# cons_profile['hijos'] = le.fit_transform(cons_profile['hijos'])\n",
    "# cons_profile['interest'] = le.fit_transform(cons_profile['interest'])\n",
    "# cons_profile['personality'] = le.fit_transform(cons_profile['personality'])\n",
    "# cons_profile['religion'] = le.fit_transform(cons_profile['religion'])\n",
    "# cons_profile['activity'] = le.fit_transform(cons_profile['activity'])\n",
    "# cons_profile['color'] = le.fit_transform(cons_profile['color'])\n",
    "# cons_profile['budget'] = le.fit_transform(cons_profile['budget'])\n",
    "# cons_profile['Upayment'] = le.fit_transform(cons_profile['Upayment'])\n",
    "# cons_profile['Rcuisine'] = le.fit_transform(cons_profile['Rcuisine'])\n",
    "\n",
    "\n",
    "# rest_final['Rpayment'] = le.fit_transform(rest_final['Rpayment'])\n",
    "# rest_final['parking_lot'] = le.fit_transform(rest_final['parking_lot'])\n",
    "# rest_final['Rcuisine'] = le.fit_transform(rest_final['Rcuisine'])\n",
    "# rest_final['days'] = le.fit_transform(rest_final['days'])\n",
    "# rest_final['the_geom_meter'] = le.fit_transform(rest_final['the_geom_meter'])\n",
    "# rest_final['name'] = le.fit_transform(rest_final['name'])\n",
    "# rest_final['smoking_area'] = le.fit_transform(rest_final['smoking_area'])\n",
    "# rest_final['dress_code'] = le.fit_transform(rest_final['dress_code'])\n",
    "# rest_final['price'] = le.fit_transform(rest_final['price'])\n",
    "# rest_final['alcohol'] = le.fit_transform(rest_final['alcohol'])\n",
    "# rest_final['Rambience'] = le.fit_transform(rest_final['Rambience'])\n",
    "# rest_final['accessibility'] = le.fit_transform(rest_final['accessibility'])\n",
    "# rest_final['franchise'] = le.fit_transform(rest_final['franchise'])\n",
    "# rest_final['area'] = le.fit_transform(rest_final['area'])\n",
    "# rest_final['other_services'] = le.fit_transform(rest_final['other_services'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "cons_profile = shuffle(cons_profile)\n",
    "test_size = int(0.3*len(cons_profile))\n",
    "cons_test = cons_profile[-test_size:]\n",
    "cons_train = cons_profile[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(cons_train['latitude'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18.895187  23.73944   22.137072  23.752265  23.730569  23.728798\n",
      "  22.137178  22.137343  22.150891  22.174624  22.179865  18.871674  22.15\n",
      "  18.867     23.752943  18.935191  18.839671  22.142208  22.303308\n",
      "  22.125786  22.149607  23.77103   22.190949  22.195826  22.138055\n",
      "  22.153385  18.877719  22.205802  22.156469  23.738067  22.162562\n",
      "  23.751607  18.95298   22.19204   22.143289  22.142429  23.735698\n",
      "  23.753336  22.122989  22.12676 ]\n"
     ]
    }
   ],
   "source": [
    "print(cons_train['latitude'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.cut(cons_train['latitude'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21.305, 23.771]    34\n",
      "(18.835, 21.305]     7\n",
      "Name: latitude, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(temp.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cons_train['latitude'] = pd.cut(cons_train['latitude'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39     (18.835, 21.305]\n",
      "93     (21.305, 23.771]\n",
      "123    (21.305, 23.771]\n",
      "102    (21.305, 23.771]\n",
      "20     (21.305, 23.771]\n",
      "Name: latitude, dtype: category\n",
      "Categories (2, interval[float64]): [(18.835, 21.305] < (21.305, 23.771]]\n"
     ]
    }
   ],
   "source": [
    "print(cons_train['latitude'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.cut(cons_train['longitude'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-101.057, -100.094]    24\n",
      "(-100.094, -99.134]     17\n",
      "Name: longitude, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(temp.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cons_train['longitude'] = pd.cut(cons_train['longitude'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    userID          latitude             longitude smoker     drink_level  \\\n",
      "39   U1040  (18.835, 21.305]   (-100.094, -99.134]  false      abstemious   \n",
      "93   U1094  (21.305, 23.771]   (-100.094, -99.134]  false      abstemious   \n",
      "123  U1124  (21.305, 23.771]  (-101.057, -100.094]  false  casual drinker   \n",
      "102  U1103  (21.305, 23.771]   (-100.094, -99.134]  false      abstemious   \n",
      "20   U1021  (21.305, 23.771]   (-100.094, -99.134]  false  social drinker   \n",
      "\n",
      "    dress_preference ambience  transport marital_status        hijos  \\\n",
      "39     no preference  friends     public         single  independent   \n",
      "93          informal  friends     public         single  independent   \n",
      "123         informal  friends     public         single  independent   \n",
      "102           formal  friends     public         single  independent   \n",
      "20     no preference   family  car owner         single    dependent   \n",
      "\n",
      "     birth_year    interest        personality  religion      activity  \\\n",
      "39         1994        none  thrifty-protector  Catholic       student   \n",
      "93         1991     variety  thrifty-protector  Catholic       student   \n",
      "123        1991        none        hard-worker  Catholic       student   \n",
      "102        1989  technology        hard-worker    Jewish  professional   \n",
      "20         1984        none        hard-worker  Catholic       student   \n",
      "\n",
      "      color  weight  budget  \n",
      "39     blue      73  medium  \n",
      "93    green      59  medium  \n",
      "123    blue      51     low  \n",
      "102   green     120  medium  \n",
      "20   purple     108  medium  \n"
     ]
    }
   ],
   "source": [
    "print(cons_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_users = []\n",
    "for index,row in cons_train.iterrows():\n",
    "    train_users.append(row[0])\n",
    "test_users = []\n",
    "for index,row in cons_test.iterrows():\n",
    "    test_users.append(row[0])\n",
    "\n",
    "sample_user = random.choice(test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similar_user(userid):\n",
    "    info  = []\n",
    "    for index,row in cons_test.iterrows():\n",
    "        if row['userID'] == userid:\n",
    "            for attr in row:\n",
    "                info.append(attr)\n",
    "    users = {}\n",
    "    res = []\n",
    "    count=0\n",
    "    points = 0\n",
    "    maxi = 0\n",
    "    similar = ''\n",
    "    for index,row in cons_train.iterrows():\n",
    "        points = 0\n",
    "        for i in range(len(row)-1):\n",
    "            if i == 1 or i==2:\n",
    "                if info[i] in row[i]:\n",
    "                    points+=1\n",
    "            if info[i] == row[i]:\n",
    "                points+=1\n",
    "        users[row[0]] = points\n",
    "        \n",
    "    for userid, value in sorted(users.items(), key=lambda x: x[1], reverse = True)[:5]:\n",
    "        res.append(userid)\n",
    "    return res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1111 132845 2 2 1\n",
      "U1111 135071 2 2 2\n",
      "U1111 132858 1 1 1\n",
      "U1111 132854 2 2 2\n",
      "U1111 132877 1 1 1\n",
      "U1111 132851 2 1 0\n",
      "U1111 135108 2 1 0\n",
      "U1111 132869 0 0 0\n",
      "U1111 132870 0 0 0\n",
      "U1111 132847 0 0 0\n",
      "U1111 135082 1 0 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rating)):\n",
    "    if rating.userID[i] == 'U1111':\n",
    "        print(rating.userID[i], rating.placeID[i], rating.rating[i], rating.food_rating[i], rating.service_rating[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maximum(usr):\n",
    "    max = 0\n",
    "    temp =  rating\n",
    "    MaxList = []\n",
    "    avg = []\n",
    "    x = []\n",
    "    for i in range(len(rating)):\n",
    "        if(rating.userID[i] == usr):\n",
    "            average = (rating.rating[i] + rating.food_rating[i] + rating.service_rating[i])/3\n",
    "            avg.append(average)\n",
    "            col = temp.loc[: , \"rating\":\"service_rating\"]\n",
    "            x = col.mean(numeric_only=True, axis=1)\n",
    "            temp['average'] = x\n",
    "    avg.sort(reverse = True)\n",
    "    for i in range(len(rating)):\n",
    "        if(temp.userID[i] == usr):\n",
    "            if(avg[0] == temp.average[i] and avg[0] != 0):\n",
    "                MaxList.append(rating.placeID[i])\n",
    "    return MaxList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135032, 135038, 132862, 132921, 135055, 132958, 135046, 135028, 132862, 132733]\n"
     ]
    }
   ],
   "source": [
    "rest = []\n",
    "userList = similar_user(sample_user)\n",
    "place = {}\n",
    "i=0\n",
    "for value in userList:\n",
    "    val = maximum(value)\n",
    "    for placeid in val:\n",
    "        rest.append(placeid)\n",
    "# print(len(place))\n",
    "# maximum('U1129')\n",
    "print(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   placeID             Rpayment\n",
      "0   135110                 cash\n",
      "1   135110                 VISA\n",
      "2   135110  MasterCard-Eurocard\n",
      "3   135110     American_Express\n",
      "4   135110     bank_debit_cards\n"
     ]
    }
   ],
   "source": [
    "print(rest_pay.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cash'}\n",
      "{135032: {'MasterCard-Eurocard', 'VISA', 'cash'}, 135038: {'cash'}, 132862: {'MasterCard-Eurocard', 'bank_debit_cards', 'VISA', 'cash', 'American_Express'}, 132921: {'cash'}, 135055: {'MasterCard-Eurocard', 'American_Express', 'VISA', 'cash'}, 132958: {'MasterCard-Eurocard', 'bank_debit_cards', 'VISA', 'cash', 'American_Express'}, 135046: {'MasterCard-Eurocard', 'VISA', 'cash'}, 135028: {'MasterCard-Eurocard', 'American_Express', 'VISA', 'cash'}, 132733: {'MasterCard-Eurocard', 'bank_debit_cards', 'VISA', 'cash'}}\n"
     ]
    }
   ],
   "source": [
    "upay = set()\n",
    "for index,row in cons_pay.iterrows():\n",
    "    if row[0] == sample_user:\n",
    "        upay.add(row[1])\n",
    "print(upay)\n",
    "\n",
    "rpay = {}\n",
    "\n",
    "\n",
    "for value in rest:\n",
    "    rset = set()\n",
    "    for index, row in rest_pay.iterrows():\n",
    "        if row[0] == value:\n",
    "            rset.add(row[1])\n",
    "    rpay[value] = rset\n",
    "        \n",
    "print(rpay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tex-Mex'}\n",
      "{135032: {'Cafeteria', 'Contemporary'}, 135038: set(), 132862: {'International'}, 132921: {'Bar'}, 135055: {'Mexican'}, 132958: {'American'}, 135046: {'Fast_Food'}, 135028: {'Mexican'}, 132733: {'Pizzeria'}}\n"
     ]
    }
   ],
   "source": [
    "ucuisine = set()\n",
    "for index,row in cons_cuisine.iterrows():\n",
    "    if row[0] == sample_user:\n",
    "        ucuisine.add(row[1])\n",
    "print(ucuisine)\n",
    "\n",
    "rcuisine = {}\n",
    "\n",
    "\n",
    "for value in rest:\n",
    "    rset = set()\n",
    "    for index, row in rest_cuisine.iterrows():\n",
    "        if row[0] == value:\n",
    "            rset.add(row[1])\n",
    "    rcuisine[value] = rset\n",
    "        \n",
    "print(rcuisine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['userID', 'latitude', 'longitude', 'smoker', 'drink_level',\n",
      "       'dress_preference', 'ambience', 'transport', 'marital_status', 'hijos',\n",
      "       'birth_year', 'interest', 'personality', 'religion', 'activity',\n",
      "       'color', 'weight', 'budget'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(cons_profile.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['public' 'car owner' 'on foot']\n"
     ]
    }
   ],
   "source": [
    "print(cons_profile['transport'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['placeID', 'parking_lot'], dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_parking.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['placeID', 'hours', 'days'], dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_hours.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['placeID', 'latitude', 'longitude', 'the_geom_meter', 'name', 'address',\n",
       "       'city', 'state', 'country', 'fax', 'zip', 'alcohol', 'smoking_area',\n",
       "       'dress_code', 'accessibility', 'price', 'url', 'Rambience', 'franchise',\n",
       "       'area', 'other_services'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_geo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   placeID parking_lot\n",
      "0   135111      public\n",
      "1   135110        none\n",
      "2   135109        none\n",
      "3   135108        none\n",
      "4   135107        none\n"
     ]
    }
   ],
   "source": [
    "print(rest_parking.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['public' 'none' 'yes' 'valet parking' 'fee' 'street' 'validated parking']\n"
     ]
    }
   ],
   "source": [
    "print(rest_parking['parking_lot'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'car owner'}\n",
      "{135032: {'public'}, 135038: {'none'}, 132862: {'valet parking'}, 132921: {'none'}, 135055: {'yes'}, 132958: {'none'}, 135046: {'yes'}, 135028: {'none'}, 132733: {'yes'}}\n"
     ]
    }
   ],
   "source": [
    "uparking = set()\n",
    "for index,row in cons_profile.iterrows():\n",
    "    if row[0] == sample_user:\n",
    "        uparking.add(row[7])\n",
    "print(uparking)\n",
    "\n",
    "rparking = {}\n",
    "\n",
    "\n",
    "for value in rest:\n",
    "    rset = set()\n",
    "    for index, row in rest_parking.iterrows():\n",
    "        if row[0] == value:\n",
    "            rset.add(row[1])\n",
    "    rparking[value] = rset\n",
    "        \n",
    "print(rparking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U1090'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car owner\n"
     ]
    }
   ],
   "source": [
    "for index,row in cons_profile.iterrows():\n",
    "    if row[0] == sample_user:\n",
    "        print(row[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['placeID', 'latitude', 'longitude', 'the_geom_meter', 'name', 'address',\n",
       "       'city', 'state', 'country', 'fax', 'zip', 'alcohol', 'smoking_area',\n",
       "       'dress_code', 'accessibility', 'price', 'url', 'Rambience', 'franchise',\n",
       "       'area', 'other_services'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_geo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userID', 'latitude', 'longitude', 'smoker', 'drink_level',\n",
       "       'dress_preference', 'ambience', 'transport', 'marital_status', 'hijos',\n",
       "       'birth_year', 'interest', 'personality', 'religion', 'activity',\n",
       "       'color', 'weight', 'budget'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_profile.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
